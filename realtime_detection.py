import cv2
import tensorflow as tf
import numpy as np
import time
import os
from collections import deque

MODEL_PATH = 'models/final_face_detector_model.h5'
IMG_WIDTH, IMG_HEIGHT = 120, 120
CONFIDENCE_THRESHOLD = 0.75
FPS_DISPLAY_INTERVAL = 1
SMOOTHING_FRAMES = 5
WINDOW_NAME = "DetecÃ§Ã£o de Face em Tempo Real - Pressione Q para sair"


if not os.path.exists(MODEL_PATH):
    print(f"âŒ Erro: Modelo nÃ£o encontrado em {MODEL_PATH}.")
    print("âž¡ï¸ Verifique o caminho e se o modelo foi salvo corretamente.")
    exit(1)

try:
    model = tf.keras.models.load_model(MODEL_PATH)
    print(f"âœ… Modelo carregado com sucesso: {MODEL_PATH}")
except Exception as e:
    print(f"âŒ Erro ao carregar o modelo: {e}")
    print("âž¡ï¸ Verifique compatibilidade de versÃµes do TensorFlow/Keras.")
    exit(1)

bbox_history = deque(maxlen=SMOOTHING_FRAMES)



def preprocess_frame(frame: np.ndarray) -> np.ndarray:
    """PrÃ©-processa o frame para entrada no modelo."""
    if len(frame.shape) == 2:
        frame = cv2.cvtColor(frame, cv2.COLOR_GRAY2BGR)
    elif frame.shape[2] == 4:
        frame = cv2.cvtColor(frame, cv2.COLOR_BGRA2BGR)

    resized = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))
    normalized = resized.astype("float32") / 255.0
    return np.expand_dims(normalized, axis=0)


def draw_bbox_and_info(frame, bbox_coords, confidence, img_width, img_height, color=(0, 255, 0)):
    """Desenha a bounding box e informaÃ§Ãµes de confianÃ§a no frame."""
    try:
        x_min, y_min, x_max, y_max = np.multiply(bbox_coords, [img_width, img_height, img_width, img_height]).astype(int)
        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), color, 3)

        text = f"ConfianÃ§a: {confidence:.2f}"
        text_size = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, 0.7, 2)[0]
        text_x = max(0, x_min)
        text_y = max(text_size[1] + 5, y_min - 10)
        cv2.putText(frame, text, (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2, cv2.LINE_AA)

        return frame, (x_min, y_min, x_max, y_max)
    except Exception as e:
        print(f"âš ï¸ Erro ao desenhar bounding box: {e}")
        return frame, None


def main():
    cap = cv2.VideoCapture(0, cv2.CAP_V4L2)

    if not cap.isOpened():
        print("\n" + "=" * 50)
        print("âŒ ERRO: NÃ£o foi possÃ­vel acessar a cÃ¢mera!")
        print("âž¡ï¸ Verifique:")
        print("1. Se a cÃ¢mera estÃ¡ conectada.")
        print("2. Se outro programa nÃ£o estÃ¡ usando a cÃ¢mera.")
        print("3. Se vocÃª tem permissÃ£o (use: sudo usermod -a -G video $USER && reboot).")
        print("4. Se os drivers estÃ£o instalados.")
        print("5. Tente trocar o Ã­ndice da cÃ¢mera (cv2.VideoCapture(1), etc.).")
        print("=" * 50 + "\n")
        return

    print("ðŸ“· CÃ¢mera aberta com sucesso. Pressione 'q' para sair.")

    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

    fps_start_time = time.time()
    fps_frame_count = 0
    current_fps = 0

    while True:
        ret, frame = cap.read()
        if not ret:
            print("âš ï¸ Aviso: NÃ£o foi possÃ­vel capturar frame da cÃ¢mera.")
            time.sleep(0.1)
            continue

        frame = cv2.flip(frame, 1)

        input_frame = preprocess_frame(frame)

        predictions = model.predict(input_frame, verbose=0)

        class_prediction, bbox_prediction = None, None
        if isinstance(predictions, list) and len(predictions) == 2:
            class_prediction = predictions[0][0][0]
            bbox_prediction = predictions[1][0]
        elif isinstance(predictions, np.ndarray) and predictions.shape[-1] == 5:
            class_prediction = predictions[0][0]
            bbox_prediction = predictions[0][1:]
        else:
            print("âš ï¸ SaÃ­da inesperada do modelo:", predictions)
            break

        detected_bbox_on_frame = None

        if class_prediction is not None and class_prediction > CONFIDENCE_THRESHOLD:
            bbox_history.append(bbox_prediction)
            smoothed_bbox = np.mean(bbox_history, axis=0)

            frame, detected_bbox_on_frame = draw_bbox_and_info(
                frame, smoothed_bbox, class_prediction, frame_width, frame_height, color=(0, 255, 0)
            )
            cv2.putText(frame, "Face Detectada!", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2, cv2.LINE_AA)
        else:
            bbox_history.clear()
            cv2.putText(frame, "Aguardando Face...", (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2, cv2.LINE_AA)

        fps_frame_count += 1
        if (time.time() - fps_start_time) > FPS_DISPLAY_INTERVAL:
            current_fps = fps_frame_count / (time.time() - fps_start_time)
            fps_start_time = time.time()
            fps_frame_count = 0

        cv2.putText(frame, f"FPS: {int(current_fps)}", (frame_width - 180, 50),
                    cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)

        cv2.imshow(WINDOW_NAME, frame)

        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("ðŸ›‘ DetecÃ§Ã£o de face interrompida pelo usuÃ¡rio.")
            break

    cap.release()
    cv2.destroyAllWindows()
    print("âœ… DetecÃ§Ã£o de face finalizada.")


if __name__ == '__main__':
    main()